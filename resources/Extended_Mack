\documentclass[varwidth]{standalone}
\usepackage{amsmath}
\usepackage{amssymb}

\begin{document}
Extended Mackintosh model equations:

\begin{align}
\Delta V_S^{n+1} = \alpha_S^n \beta^+ \cdot \left( 1 - \partial V^n_S \right) \cdot \left| R^n \right| \\
\overline{\Delta V_S^{n+1}} = \alpha_S^n \beta^- \cdot \left( 1 + \partial V^n_S \right) \cdot \left| R^n \right| \\
\partial V^n_S = V^n_S - \overline{V^n_S} \\
\alpha_S^{n+1} = \alpha_S^n + \Delta \alpha^{n+1}_S \,\,\,\text{when}\,\,\, R_S^n > 0 \\
\alpha_S^{n+1} = \alpha_S^n + \overline{\Delta \alpha^{n+1}_S} \,\,\,\text{when}\,\,\, R_S^n < 0 \\
\Delta \alpha_S^{n+1} = - \theta^+ \cdot \left( \Lambda^+ - \Lambda^- \right) \\
\overline{\Delta \alpha_S^{n+1}} = - \theta^- \cdot \left( \mathcal{R^+} - \mathcal{R^-} \right) \\
\Lambda^+ = \big| \lambda^n - V_S^n + \overline{V^n_S} \big| \\
\Lambda^- = \big|\lambda^n - \sum_{i\neq A} \left( V_i^n + \overline{V_i^n} \right) \big| \\
\mathcal{R^+} = \left| \left| R^n \right| + V_S^n - \overline{V^n_S} \right| \\
\mathcal{R^-} = \left| \left| R^n \right| + \sum_{i\neq A} \big( V_i^n - \overline{V_i^n} \big) \right| \\
\end{align}


\begin{description}
	\item[$\alpha_i^{n}$] = associability of the CS $i$ on trial $n$.
        \item[$\beta$] = Learning rate parameter for the US, where $\beta^+$ (excitatory) > $\beta^-$ (inhibitory)
	\item[$\lambda_i^n$] = intensity of the US with stimuli i at trial n.
	\item[$V_{i,j}^{n + 1}$] = associative strength of the CS $i$ on trial $n + 1$.
        \item[$\overline{V_{i,j}^{n+1}}$] = inhibitory associative strength of the CS $i$ on trial $n + 1$.
	\item[$\theta$] = learning-rate parameters for changes in $\alpha$ on excitatory and inhibitory trials. $\theta^E$ (excitatory) > $\theta^I$ (inhibitory)
    \item[$R$] = Reinforcing value (excitatory/inhibitory)
\end{description} \vspace{10pt}

\end{document}